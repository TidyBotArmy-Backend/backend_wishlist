{
  "updated": "2026-02-15T08:59:00Z",
  "capabilities": {
    "yolo-detection": {
      "type": "model",
      "description": "YOLO object detection and instance segmentation. Supports multiple model sizes (nano to xlarge). Returns bounding boxes, class labels, confidence scores, and optional segmentation masks (polygon, RLE, or bitmap).",
      "service_repo": "https://github.com/TidyBot-Services/yolo-service",
      "client_sdk": "https://raw.githubusercontent.com/TidyBot-Services/yolo-service/main/client.py",
      "api_docs": "https://github.com/TidyBot-Services/yolo-service/blob/main/README.md",
      "host": "http://158.130.109.188:8000",
      "endpoints": [
        "GET /health",
        "POST /detect",
        "GET /docs"
      ],
      "models": [
        "yolov8n",
        "yolov8s",
        "yolov8m",
        "yolov8l",
        "yolov8x",
        "yolov8n-seg",
        "yolov8s-seg"
      ],
      "added_by": "steve",
      "added_at": "2026-02-13",
      "version": "0.2.0"
    },
    "grounded-sam2": {
      "type": "model",
      "description": "Open-vocabulary object detection (Grounding DINO) + segmentation (SAM 2). Accepts images and text prompts, returns bounding boxes, segmentation masks, and confidence scores.",
      "service_repo": "https://github.com/TidyBot-Services/grounded-sam2-service",
      "client_sdk": "https://raw.githubusercontent.com/TidyBot-Services/grounded-sam2-service/main/client.py",
      "api_docs": "https://github.com/TidyBot-Services/grounded-sam2-service/blob/main/README.md",
      "host": "http://158.130.109.188:8001",
      "endpoints": [
        "GET /health",
        "POST /detect",
        "GET /docs"
      ],
      "models": [
        "grounding-dino-tiny",
        "sam2.1-hiera-large"
      ],
      "added_by": "steve",
      "added_at": "2026-02-14",
      "version": "0.1.0",
      "usage": {
        "import": "from services.grounded_sam2.client import GroundedSAM2Client",
        "example": "client = GroundedSAM2Client()\ndetections = client.detect(image_bytes, prompts=['red cup'])",
        "returns": "List of dicts with keys: label, confidence, bbox {x1,y1,x2,y2}"
      }
    },
    "graspgen": {
      "type": "model",
      "description": "6-DOF grasp pose generation using Contact-GraspNet. Accepts depth images (optionally with object mask) and returns ranked candidate grasp poses as 4x4 homogeneous transforms with quality scores. Suitable for direct use with Franka arm.",
      "service_repo": "https://github.com/TidyBot-Services/graspgen-service",
      "client_sdk": "https://raw.githubusercontent.com/TidyBot-Services/graspgen-service/main/client.py",
      "api_docs": "https://github.com/TidyBot-Services/graspgen-service/blob/main/README.md",
      "host": "http://158.130.109.188:8002",
      "endpoints": [
        "GET /health",
        "POST /generate",
        "GET /docs"
      ],
      "models": [
        "contact-graspnet-pytorch"
      ],
      "added_by": "steve",
      "added_at": "2026-02-14",
      "version": "0.1.0",
      "usage": {
        "import": "from services.graspgen.client import GraspGenClient",
        "example": "client = GraspGenClient()\ngrasps = client.generate(depth_bytes, num_grasps=10)",
        "returns": "List of dicts with keys: transform (4x4), score, contact_point [x,y,z], gripper_opening"
      }
    },
    "foundation-stereo": {
      "type": "model",
      "description": "Zero-shot stereo depth estimation using FoundationStereo (CVPR 2025). Accepts rectified stereo image pairs and returns dense disparity maps and metric depth in meters. Handles reflective/transparent surfaces where IR stereo fails.",
      "service_repo": "https://github.com/TidyBot-Services/foundation-stereo-service",
      "client_sdk": "https://raw.githubusercontent.com/TidyBot-Services/foundation-stereo-service/master/client.py",
      "api_docs": "https://github.com/TidyBot-Services/foundation-stereo-service/blob/master/README.md",
      "host": "http://158.130.109.188:8003",
      "endpoints": [
        "GET /health",
        "POST /depth",
        "GET /docs"
      ],
      "models": [
        "foundation-stereo-vitl-23-51-11"
      ],
      "added_by": "steve",
      "added_at": "2026-02-14",
      "version": "1.0.0",
      "usage": {
        "import": "from services.foundation_stereo.client import FoundationStereoClient",
        "example": "client = FoundationStereoClient()\nresult = client.depth(left_bytes, right_bytes, focal_length=382.5, baseline=0.055)",
        "returns": "Dict with depth (np.ndarray HxW float32 meters), disparity (np.ndarray), inference_ms"
      }
    },
    "nav-mapping": {
      "type": "service",
      "description": "2D occupancy grid mapping from depth images + robot pose. A* path planning with obstacle inflation and frontier detection for autonomous exploration.",
      "service_repo": "https://github.com/TidyBot-Services/nav-mapping-service",
      "client_sdk": "https://raw.githubusercontent.com/TidyBot-Services/nav-mapping-service/master/client.py",
      "api_docs": "https://github.com/TidyBot-Services/nav-mapping-service/blob/master/README.md",
      "host": "http://158.130.109.188:8004",
      "endpoints": [
        "GET /health",
        "POST /update",
        "GET /map",
        "POST /plan",
        "GET /frontiers",
        "POST /reset"
      ],
      "added_by": "steve",
      "added_at": "2026-02-15",
      "version": "0.1.0",
      "usage": {
        "import": "from services.nav_mapping.client import NavMappingClient",
        "example": "client = NavMappingClient()\nclient.update(depth_bytes, pose=(x, y, theta), intrinsics=(fx, fy, cx, cy))",
        "returns": "Dict with update status, timing"
      }
    }
  }
}
